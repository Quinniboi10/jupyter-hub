{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20774/2654761357.py:7: DtypeWarning: Columns (0: chain) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_label_df = pd.read_csv(\"./datasets/stanford-rna-3d-folding-2/train_labels.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>chain</th>\n",
       "      <th>copy</th>\n",
       "      <th>target_id</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157D_1</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>4.843</td>\n",
       "      <td>-5.640</td>\n",
       "      <td>13.265</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>157D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157D_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>3.385</td>\n",
       "      <td>-7.613</td>\n",
       "      <td>8.267</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>157D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157D_3</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>2.158</td>\n",
       "      <td>-6.751</td>\n",
       "      <td>2.949</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>157D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>157D_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>2.669</td>\n",
       "      <td>-4.843</td>\n",
       "      <td>-1.773</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>157D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>157D_5</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>3.509</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-4.045</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>157D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID resname  resid    x_1    y_1     z_1 chain  copy target_id  valid\n",
       "0  157D_1       C      1  4.843 -5.640  13.265     A     1      157D   True\n",
       "1  157D_2       G      2  3.385 -7.613   8.267     A     1      157D   True\n",
       "2  157D_3       C      3  2.158 -6.751   2.949     A     1      157D   True\n",
       "3  157D_4       G      4  2.669 -4.843  -1.773     A     1      157D   True\n",
       "4  157D_5       A      5  3.509  0.239  -4.045     A     1      157D   True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import isnan\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "train_seq_df = pd.read_csv(\"./datasets/stanford-rna-3d-folding-2/train_sequences.csv\")\n",
    "train_label_df = pd.read_csv(\"./datasets/stanford-rna-3d-folding-2/train_labels.csv\")\n",
    "\n",
    "train_label_df[\"chain\"] = train_label_df[\"chain\"].astype(str)\n",
    "train_label_df['target_id'] = train_label_df['ID'].str.split('_', n=1).str[0]\n",
    "\n",
    "nan_mask = train_label_df[['x_1','y_1','z_1']].isna().any(axis=1)\n",
    "train_label_df['valid'] = ~nan_mask\n",
    "\n",
    "train_label_df = train_label_df.sort_values([\"target_id\", \"chain\", \"copy\", \"resid\"]).reset_index(drop=True)\n",
    "\n",
    "train_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20774/3724868088.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid_label_df['target_id'] = valid_label_df['ID'].str.split('_', n=1).str[0]\n",
      "/tmp/ipykernel_20774/3724868088.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  valid_label_df['valid'] = ~nan_mask\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>...</th>\n",
       "      <th>y_39</th>\n",
       "      <th>z_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>y_40</th>\n",
       "      <th>z_40</th>\n",
       "      <th>chain</th>\n",
       "      <th>copy</th>\n",
       "      <th>Usage</th>\n",
       "      <th>target_id</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ZNQ_1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.054</td>\n",
       "      <td>-15.062</td>\n",
       "      <td>20.736</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Public</td>\n",
       "      <td>8ZNQ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8ZNQ_2</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.971</td>\n",
       "      <td>-15.076</td>\n",
       "      <td>15.338</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Public</td>\n",
       "      <td>8ZNQ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ZNQ_3</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.350</td>\n",
       "      <td>-13.497</td>\n",
       "      <td>10.444</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Public</td>\n",
       "      <td>8ZNQ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8ZNQ_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.443</td>\n",
       "      <td>-11.044</td>\n",
       "      <td>6.605</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Public</td>\n",
       "      <td>8ZNQ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8ZNQ_5</td>\n",
       "      <td>U</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.350</td>\n",
       "      <td>-6.269</td>\n",
       "      <td>4.550</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>-1.000000e+18</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>Public</td>\n",
       "      <td>8ZNQ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID resname  resid    x_1     y_1     z_1           x_2           y_2  \\\n",
       "0  8ZNQ_1       A      1 -2.054 -15.062  20.736 -1.000000e+18 -1.000000e+18   \n",
       "1  8ZNQ_2       C      2 -1.971 -15.076  15.338 -1.000000e+18 -1.000000e+18   \n",
       "2  8ZNQ_3       C      3 -3.350 -13.497  10.444 -1.000000e+18 -1.000000e+18   \n",
       "3  8ZNQ_4       G      4 -5.443 -11.044   6.605 -1.000000e+18 -1.000000e+18   \n",
       "4  8ZNQ_5       U      5 -6.350  -6.269   4.550 -1.000000e+18 -1.000000e+18   \n",
       "\n",
       "            z_2           x_3  ...          y_39          z_39          x_40  \\\n",
       "0 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
       "1 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
       "2 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
       "3 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
       "4 -1.000000e+18 -1.000000e+18  ... -1.000000e+18 -1.000000e+18 -1.000000e+18   \n",
       "\n",
       "           y_40          z_40  chain  copy   Usage  target_id  valid  \n",
       "0 -1.000000e+18 -1.000000e+18      A     1  Public       8ZNQ   True  \n",
       "1 -1.000000e+18 -1.000000e+18      A     1  Public       8ZNQ   True  \n",
       "2 -1.000000e+18 -1.000000e+18      A     1  Public       8ZNQ   True  \n",
       "3 -1.000000e+18 -1.000000e+18      A     1  Public       8ZNQ   True  \n",
       "4 -1.000000e+18 -1.000000e+18      A     1  Public       8ZNQ   True  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_seq_df = pd.read_csv(\"./datasets/stanford-rna-3d-folding-2/validation_sequences.csv\")\n",
    "valid_label_df = pd.read_csv(\"./datasets/stanford-rna-3d-folding-2/validation_labels.csv\")\n",
    "\n",
    "valid_label_df[\"chain\"] = valid_label_df[\"chain\"].astype(str)\n",
    "valid_label_df['target_id'] = valid_label_df['ID'].str.split('_', n=1).str[0]\n",
    "\n",
    "nan_mask = valid_label_df[['x_1','y_1','z_1']].isna().any(axis=1) | (valid_label_df[['x_1','y_1','z_1']] <= -1e17).any(axis=1)\n",
    "valid_label_df['valid'] = ~nan_mask\n",
    "\n",
    "valid_label_df = valid_label_df.sort_values([\"target_id\", \"chain\", \"copy\", \"resid\"]).reset_index(drop=True)\n",
    "\n",
    "valid_label_df = valid_label_df.copy()\n",
    "valid_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AAA': 1, 'AAC': 2, 'AAG': 3, 'AAU': 4, 'AA ': 5, 'ACA': 6, 'ACC': 7, 'ACG': 8, 'ACU': 9, 'AC ': 10, 'AGA': 11, 'AGC': 12, 'AGG': 13, 'AGU': 14, 'AG ': 15, 'AUA': 16, 'AUC': 17, 'AUG': 18, 'AUU': 19, 'AU ': 20, 'CAA': 21, 'CAC': 22, 'CAG': 23, 'CAU': 24, 'CA ': 25, 'CCA': 26, 'CCC': 27, 'CCG': 28, 'CCU': 29, 'CC ': 30, 'CGA': 31, 'CGC': 32, 'CGG': 33, 'CGU': 34, 'CG ': 35, 'CUA': 36, 'CUC': 37, 'CUG': 38, 'CUU': 39, 'CU ': 40, 'GAA': 41, 'GAC': 42, 'GAG': 43, 'GAU': 44, 'GA ': 45, 'GCA': 46, 'GCC': 47, 'GCG': 48, 'GCU': 49, 'GC ': 50, 'GGA': 51, 'GGC': 52, 'GGG': 53, 'GGU': 54, 'GG ': 55, 'GUA': 56, 'GUC': 57, 'GUG': 58, 'GUU': 59, 'GU ': 60, 'UAA': 61, 'UAC': 62, 'UAG': 63, 'UAU': 64, 'UA ': 65, 'UCA': 66, 'UCC': 67, 'UCG': 68, 'UCU': 69, 'UC ': 70, 'UGA': 71, 'UGC': 72, 'UGG': 73, 'UGU': 74, 'UG ': 75, 'UUA': 76, 'UUC': 77, 'UUG': 78, 'UUU': 79, 'UU ': 80, ' AA': 81, ' AC': 82, ' AG': 83, ' AU': 84, ' A ': 85, ' CA': 86, ' CC': 87, ' CG': 88, ' CU': 89, ' C ': 90, ' GA': 91, ' GC': 92, ' GG': 93, ' GU': 94, ' G ': 95, ' UA': 96, ' UC': 97, ' UG': 98, ' UU': 99, ' U ': 100}\n"
     ]
    }
   ],
   "source": [
    "# Map a 3 letter sequence to\n",
    "# a value for embedding\n",
    "def get_token_map():\n",
    "    token_map = {}\n",
    "    tokens = \"ACGU \"\n",
    "    i = 1\n",
    "    for c1 in tokens:\n",
    "        for c2 in tokens:\n",
    "            if c2 == ' ':\n",
    "                continue\n",
    "            for c3 in tokens:\n",
    "                token_map[c1 + c2 + c3] = i\n",
    "                i += 1\n",
    "    return token_map\n",
    "\n",
    "token_map = get_token_map()\n",
    "\n",
    "print(token_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e5cf5a3f514d9abc07f52409c86329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build id->coordinate map:   0%|          | 0/7794971 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081d12e42e934c7aae6d2beb6fd87d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Build id->coordinate map:   0%|          | 0/9762 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std : (213.1497, 212.8262, 207.3829)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaa03b15c5b4c90a636d53af0f9a060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalize deltas:   0%|          | 0/17905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average subcomponent magnitude: 1.559521499174416\n",
      "Min: -4.4135744661340635\n",
      "Max: 6.317545359570798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3137d9df30f74db2b506d1259d41acce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalize deltas:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average subcomponent magnitude: 1.700205222690916\n",
      "Min: -0.4871928419346351\n",
      "Max: 2.028373413067239\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def build_delta_map(df):\n",
    "    id_map = {}\n",
    "    total = 0\n",
    "    min_found = 0\n",
    "    max_found = 0\n",
    "    # Builds a mask where NaNs are [None, None, None]\n",
    "    for row in tqdm(df.itertuples(index=False), desc = \"Build id->coordinate map\", total=len(df)):\n",
    "        key = (row.target_id, row.chain, row.copy)\n",
    "        if not row.valid:\n",
    "            id_map.setdefault(key, []).append([None,None,None])\n",
    "        else:\n",
    "            id_map.setdefault(key, []).append([row.x_1,row.y_1,row.z_1])\n",
    "\n",
    "    # Calculates relative distances and handles NaNs\n",
    "    # for shape in tqdm(id_map.values(), desc=\"Calculate deltas\"):\n",
    "    #     abs_coords = [p.copy() if p[0] is not None else None for p in shape]\n",
    "    \n",
    "    #     prev_abs = None\n",
    "    \n",
    "    #     for i in range(len(shape)):\n",
    "    #         if abs_coords[i] is None:\n",
    "    #             shape[i] = [None, None, None]\n",
    "    #             prev_abs = None\n",
    "    #             continue\n",
    "    \n",
    "    #         if prev_abs is None:\n",
    "    #             shape[i] = [None, None, None]\n",
    "    #         else:\n",
    "    #             shape[i] = [abs_coords[i][j] - prev_abs[j] for j in range(3)]\n",
    "    \n",
    "    #         prev_abs = abs_coords[i]\n",
    "\n",
    "    return id_map\n",
    "\n",
    "def get_stds(id_map):\n",
    "    sx = sy = sz = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for shape in id_map.values():\n",
    "        for x,y,z in shape:\n",
    "            if x is None: continue\n",
    "            sx += x*x\n",
    "            sy += y*y\n",
    "            sz += z*z\n",
    "            n += 1\n",
    "\n",
    "    std_x = math.sqrt(sx / n) or 1.0\n",
    "    std_y = math.sqrt(sy / n) or 1.0\n",
    "    std_z = math.sqrt(sz / n) or 1.0\n",
    "\n",
    "    print(f\"std : ({std_x:.4f}, {std_y:.4f}, {std_z:.4f})\")\n",
    "    return std_x, std_y, std_z\n",
    "\n",
    "def normalize(id_map, std_x, std_y, std_z):\n",
    "    total = 0\n",
    "    min_found = float(\"inf\")\n",
    "    max_found = float(\"-inf\")\n",
    "    n = 0\n",
    "\n",
    "    for shape in tqdm(id_map.values(), desc=\"Normalize deltas\"):\n",
    "        for p in shape:\n",
    "            if p[0] is None:\n",
    "                continue\n",
    "\n",
    "            p[0] /= std_x\n",
    "            p[1] /= std_y\n",
    "            p[2] /= std_z\n",
    "\n",
    "            total += math.sqrt(p[0]**2 + p[1]**2 + p[2]**2)\n",
    "            min_found = min(min_found, p[0], p[1], p[2])\n",
    "            max_found = max(max_found, p[0], p[1], p[2])\n",
    "            n += 1\n",
    "\n",
    "    print(\"Average subcomponent magnitude:\", total / n)\n",
    "    print(\"Min:\", min_found)\n",
    "    print(\"Max:\", max_found)\n",
    "\n",
    "    return id_map\n",
    "\n",
    "train_map = build_delta_map(train_label_df)\n",
    "valid_map = build_delta_map(valid_label_df)\n",
    "\n",
    "stds = get_stds(train_map)\n",
    "\n",
    "train_map = normalize(train_map, *stds)\n",
    "valid_map = normalize(valid_map, *stds)\n",
    "\n",
    "# Map (target_id, chain, copy) to a list of\n",
    "# coordinates representing the shape produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81aff8b579a4bbd8f3549c202560333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8a6d85b5534790abd4eef891dc234e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>chain</th>\n",
       "      <th>copy</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ZNQ</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9CFN</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9E74</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9E75</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9E9Q</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id chain  copy  length\n",
       "0      8ZNQ     A     1      30\n",
       "1      9CFN     A     1      59\n",
       "2      9E74     A     1     255\n",
       "3      9E75     A     1     165\n",
       "4      9E9Q     A     1     101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_example_df(id_map):\n",
    "    examples = []\n",
    "    for (tid, chain, copy), coords in tqdm(id_map.items()):\n",
    "        examples.append({\n",
    "            \"target_id\": tid,\n",
    "            \"chain\": chain,\n",
    "            \"copy\": copy,\n",
    "            \"length\": len(coords)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(examples)\n",
    "\n",
    "train_examples_df = get_example_df(train_map)\n",
    "valid_examples_df = get_example_df(valid_map)\n",
    "\n",
    "# Drop everything that Kabsch simply can't handle\n",
    "train_examples_df = train_examples_df.drop(train_examples_df[train_examples_df['length'] < 3].index)\n",
    "valid_examples_df = valid_examples_df.drop(valid_examples_df[valid_examples_df['length'] < 3].index)\n",
    "\n",
    "train_examples_df.reset_index(drop=True)\n",
    "valid_examples_df.reset_index(drop=True)\n",
    "\n",
    "train_examples_df.head()\n",
    "valid_examples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c083831503d4957903c022249794f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5029518ea44d0980b26506716e7c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./datasets/stanford-rna-3d-folding-2/extra\")\n",
    "\n",
    "from parse_fasta_py import parse_fasta\n",
    "\n",
    "# Builds a map of\n",
    "# (ID, chain) -> sequence\n",
    "def build_seq_map(df):\n",
    "    seq_map = {}\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        chains = parse_fasta(row[\"all_sequences\"])\n",
    "        for primary_chain, (seq, chain_list) in chains.items():\n",
    "            for ch in chain_list:\n",
    "                seq_map[(row[\"target_id\"], ch)] = seq\n",
    "    return seq_map\n",
    "\n",
    "train_seq_map = build_seq_map(train_seq_df)\n",
    "valid_seq_map = build_seq_map(valid_seq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence: 5229\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 0\n",
    "for seq in train_seq_map.values():\n",
    "    max_seq_len = max(max_seq_len, len(seq))\n",
    "max_seq_len += 2 # Because of padding each side\n",
    "print(\"Longest sequence:\", max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ember import Learner\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from collections import deque\n",
    "from time import time\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cuda.enable_flash_sdp(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "test_bs = 1\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_str(k, s):\n",
    "    return [s[i:i+k] for i in range(len(s)-k+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_by_id(id: str) -> str:\n",
    "    if '_' in id:\n",
    "        id = id.split('_')[0]\n",
    "    for i, row in train_seq_df.iterrows():\n",
    "        if row['target_id'] == id:\n",
    "            return row['sequence']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(seq: str):\n",
    "    str_tokens = split_str(3, seq)\n",
    "    tokens = [token_map[key] for key in str_tokens]\n",
    "    return torch.tensor(tokens, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorWrapper():\n",
    "    def __init__(self, *args):\n",
    "        self.x = args\n",
    "\n",
    "    def to(self, device, **kargs):\n",
    "        self.x = tuple(x.to(device, **kargs) for x in self.x)\n",
    "        return self\n",
    "\n",
    "    def get(self):\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNADataset(Dataset):\n",
    "    def __init__(self, example_df, id_map, seq_map):\n",
    "        self.examples = example_df\n",
    "        self.id_map = id_map\n",
    "        self.seq_map = seq_map\n",
    "\n",
    "        self.examples = self.examples[self.examples.apply(self.has_any_valid, axis=1)].reset_index(drop=True)\n",
    "\n",
    "        # Load this stuff into numpy so it's just an array index\n",
    "        # instead of a dataframe index which is way slower\n",
    "        self.target_ids = self.examples[\"target_id\"].to_numpy()\n",
    "        self.chains     = self.examples[\"chain\"].to_numpy()\n",
    "        self.copies     = self.examples[\"copy\"].to_numpy()\n",
    "\n",
    "        print(f\"Found {len(self):,} data points\")\n",
    "\n",
    "    def has_any_valid(self, row):\n",
    "        key = (row[\"target_id\"], row[\"chain\"], row[\"copy\"])\n",
    "    \n",
    "        coords = self.id_map.get(key)\n",
    "        if coords is None:\n",
    "            return False\n",
    "    \n",
    "        return sum(c[0] is not None for c in coords) >= 3\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the row from the examples dataframe\n",
    "        target_id = self.target_ids[idx]\n",
    "        chain     = self.chains[idx]\n",
    "        copy      = self.copies[idx]\n",
    "\n",
    "        # Construct the key and get a list of coordinates\n",
    "        key = (target_id, chain, copy)\n",
    "        coords = self.id_map[key]\n",
    "\n",
    "        # Get the sequence of the coordinates\n",
    "        # Pad each side so that the output head N is for the central\n",
    "        # nucleotide in 3mer N\n",
    "        seq = ' ' + self.seq_map[(target_id, chain)] + ' '\n",
    "        raw_seq = encode(seq)\n",
    "\n",
    "        clean = []\n",
    "        valid_flags = []\n",
    "\n",
    "        # Sanitize data to remove NaNs\n",
    "        # but making sure to mask them out\n",
    "        for c in coords:\n",
    "            if c[0] is None:\n",
    "                clean.append([0.0, 0.0, 0.0])\n",
    "                valid_flags.append(False)\n",
    "            else:\n",
    "                clean.append(c)\n",
    "                valid_flags.append(True)\n",
    "\n",
    "        L = len(clean)\n",
    "\n",
    "        target = torch.tensor(clean, dtype=torch.float32)\n",
    "        is_valid = torch.tensor(valid_flags, dtype=torch.bool)\n",
    "\n",
    "        seq_tensor = torch.zeros(max_seq_len, dtype=torch.long)\n",
    "        target_tensor = torch.zeros(max_seq_len, 3, dtype=torch.float32)\n",
    "        valid_tensor = torch.zeros(max_seq_len, dtype=torch.bool)\n",
    "\n",
    "        seq_tensor[:L] = raw_seq[:]\n",
    "        target_tensor[:L, :] = target[:, :]\n",
    "        valid_tensor[:L] = is_valid[:]\n",
    "\n",
    "        # Should return dimensions\n",
    "        # [len]\n",
    "        # [len]\n",
    "        # [len, 3]\n",
    "        # and then collate_fn will pad to the batch\n",
    "        assert seq_tensor.shape[0] == target_tensor.shape[0], f\"Sequence tensor has length of {seq_tensor.shape[0]} but target is {target_tensor.shape[0]}\"\n",
    "\n",
    "        return seq_tensor, valid_tensor, target_tensor\n",
    "\n",
    "    # Take a batch and stack it\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        seqs, is_valid, targets = zip(*batch)\n",
    "\n",
    "        B = len(batch)\n",
    "\n",
    "        seq_tensor = torch.zeros(B, max_seq_len, dtype=torch.long)\n",
    "        valid_tensor = torch.zeros(B, max_seq_len, dtype=torch.bool)\n",
    "        target_tensor = torch.zeros(B, max_seq_len, 3, dtype=torch.float32)\n",
    "\n",
    "        for i, (s, v, t) in enumerate(zip(seqs, is_valid, targets)):\n",
    "            seq_tensor[i] = s\n",
    "            valid_tensor[i] = v\n",
    "            target_tensor[i] = t\n",
    "    \n",
    "        return TensorWrapper(seq_tensor, valid_tensor), target_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17,678 data points\n",
      "Found 47 data points\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    RNADataset(train_examples_df, train_map, train_seq_map),\n",
    "    batch_size=bs,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    num_workers=12,\n",
    "    collate_fn=RNADataset.collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    RNADataset(valid_examples_df, valid_map, valid_seq_map),\n",
    "    batch_size=test_bs,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=RNADataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-02T21:00:35.523631Z",
     "iopub.status.busy": "2026-02-02T21:00:35.522531Z",
     "iopub.status.idle": "2026-02-02T21:00:35.542140Z",
     "shell.execute_reply": "2026-02-02T21:00:35.540436Z",
     "shell.execute_reply.started": "2026-02-02T21:00:35.523559Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(dim, dim, 5, stride=1, padding='same')\n",
    "        self.conv2 = nn.Conv1d(dim, dim, 5, stride=1, padding='same', dilation=3)\n",
    "        self.conv3 = nn.Conv1d(dim, dim, 5, stride=1, padding='same', dilation=6)\n",
    "        self.act = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, D, L)\n",
    "        # Run all conv layers as residuals\n",
    "        res = x\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.act(self.conv3(x))\n",
    "        return x + res\n",
    "\n",
    "class GlobalBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout, n_heads):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=dim,\n",
    "                nhead=n_heads,\n",
    "                dim_feedforward=4*dim,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "                norm_first=True,\n",
    "                bias=True\n",
    "            ),\n",
    "            num_layers=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x: (B, L, D)\n",
    "        x = self.encoder(x, src_key_padding_mask=mask)\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dim=128, n_heads=8, dropout=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input block\n",
    "        self.embed = nn.Embedding(len(token_map) + 1, dim, padding_idx=0)\n",
    "\n",
    "        # Relationship block\n",
    "        self.local = ConvBlock(dim)\n",
    "        self.dist = GlobalBlock(dim, dropout, n_heads)\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq):\n",
    "        seq = seq.get()[0]\n",
    "        B, L = seq.shape\n",
    "        # seq: (B, L)\n",
    "        \n",
    "        # Input block\n",
    "        mask = seq == 0\n",
    "        x = self.embed(seq) # (B, L, D)\n",
    "\n",
    "        # Relationship block\n",
    "        for _ in range(5):\n",
    "            res = x\n",
    "            x = x.transpose(-1, -2) # (B, D, L)\n",
    "            x = self.local(x) # (B, D, L)\n",
    "            x = x.transpose(-1, -2) # (B, L, D)\n",
    "\n",
    "            x = self.dist(x, mask) # Ideally this is pairwise but VRAM is hard to come by\n",
    "\n",
    "            x = self.fc1(x)\n",
    "            \n",
    "            x = x + res\n",
    "\n",
    "        # Decoding block\n",
    "        x = self.head(x) # (B, L, 3)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(nn.Module):\n",
    "    def forward(self, out, tgt):\n",
    "        x = self.learner.x\n",
    "        assert isinstance(x, TensorWrapper)\n",
    "        assert torch.isfinite(out).all(), \"out has NaNs/Infs, likely from gradient explosions\"\n",
    "        assert torch.isfinite(tgt).all(), \"tgt has NaNs/Infs, likely from input data\"\n",
    "        _, mask = x.get()\n",
    "        m = mask.unsqueeze(-1)\n",
    "        return (((out - tgt)**2) * m).sum() / (m.sum() + 1e-8)\n",
    "\n",
    "# Based on https://hunterheidenreich.com/posts/kabsch-algorithm/\n",
    "# Almost identical to the article but with masking\n",
    "\n",
    "# Also it must do all computations in f32\n",
    "# to avoid weird NaNs everywhere\n",
    "class KabschRMSDLoss(nn.Module):\n",
    "    def forward(self, out, tgt):\n",
    "        if self.learner.model.training:\n",
    "            tgt = tgt + torch.rand_like(tgt, device=tgt.device) * 0.01\n",
    "        with torch.amp.autocast(device_type=self.learner.device, enabled=False):\n",
    "            B, L, _ = out.shape\n",
    "            _, mask = self.learner.x.get()\n",
    "            m = mask.unsqueeze(-1) # (B,L,1)\n",
    "\n",
    "            out = out.to(torch.float32)\n",
    "            tgt = tgt.to(torch.float32)\n",
    "            m = m.to(torch.float32)\n",
    "\n",
    "            # First calculate the translation vector\n",
    "            # that would be applied, out and tgt\n",
    "            # are both centered\n",
    "            # Making sure to multiply by w so the\n",
    "            # bad coordinates remain masked out\n",
    "\n",
    "            # Calculates (B, 1, 1) / (B, 1, 1)\n",
    "            mu_out = (out * m).sum(dim=1, keepdim=True) / (m.sum(dim=1, keepdim=True) + 1e-8)\n",
    "            mu_tgt = (tgt * m).sum(dim=1, keepdim=True) / (m.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "            out = out - mu_out\n",
    "            tgt = tgt - mu_tgt\n",
    "\n",
    "            # Get the cross-variance matrix\n",
    "            cross_var = (out * m).transpose(-1, -2) @ (tgt * m)\n",
    "            # Then find the singular value decomposition\n",
    "            U, _, Vt = torch.linalg.svd(cross_var)\n",
    "\n",
    "            rot_mat = Vt.transpose(-1,-2) @ U.transpose(-1,-2)\n",
    "            flip = torch.det(rot_mat) < 0.0\n",
    "            if flip.any().item():\n",
    "                Vt = Vt.clone() # Clone so gradients don't get destroyed\n",
    "                Vt[flip, -1, :] *= -1.0\n",
    "                rot_mat = Vt.transpose(-1,-2) @ U.transpose(-1,-2)\n",
    "\n",
    "            out_aligned = out @ rot_mat\n",
    "            diff = (tgt - out_aligned) * m\n",
    "\n",
    "            # Making sure to average each sample\n",
    "            rmsd = torch.sqrt((diff ** 2).sum(dim=(-1, -2)) / (m.sum(dim=(-1, -2)) + 1e-8) + 1e-8) # [B]\n",
    "\n",
    "            return rmsd.mean()\n",
    "\n",
    "class PairwiseDistanceLoss(nn.Module):\n",
    "    # If K is None, then just to the entire thing\n",
    "    def __init__(self, K=512):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "\n",
    "    def forward(self, out, tgt):\n",
    "        if self.training:\n",
    "            tgt = tgt + torch.rand_like(tgt) * 0.01\n",
    "\n",
    "        _, mask = self.learner.x.get() # (B, L)\n",
    "        B, L = mask.shape\n",
    "\n",
    "        out = out * mask.unsqueeze(-1)\n",
    "        tgt = tgt * mask.unsqueeze(-1)\n",
    "\n",
    "        loss_sum = 0.0\n",
    "        mask_sum = 0.0\n",
    "\n",
    "        if self.K is None:\n",
    "            K = L\n",
    "        else:\n",
    "            K = self.K\n",
    "        for k in range(1, K + 1):\n",
    "            out_i = out[:, :-k] # (B, L-k, D)\n",
    "            out_j = out[:, k:] # (B, L-k, D)\n",
    "\n",
    "            tgt_i = tgt[:, :-k]\n",
    "            tgt_j = tgt[:, k:]\n",
    "\n",
    "            mask_i = mask[:, :-k]\n",
    "            mask_j = mask[:, k:]\n",
    "\n",
    "            pair_mask = mask_i * mask_j # (B, L-k)\n",
    "\n",
    "            # Get distances (diff then get magnitude)\n",
    "            out_dist = (out_i - out_j).norm(dim=-1)\n",
    "            tgt_dist = (tgt_i - tgt_j).norm(dim=-1)\n",
    "\n",
    "            diff = (tgt_dist - out_dist).pow(2)\n",
    "\n",
    "            loss_sum += (diff * pair_mask).sum()\n",
    "            mask_sum += pair_mask.sum()\n",
    "\n",
    "        return loss_sum / (mask_sum + 1e-8)\n",
    "\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, alpha = 0.1, beta = 1.0):\n",
    "        super().__init__()\n",
    "        self.a = alpha\n",
    "        self.b = beta\n",
    "        self.loss_a = PairwiseDistanceLoss()\n",
    "        self.loss_b = KabschRMSDLoss()\n",
    "    def forward(self, out, tgt):\n",
    "        self.loss_a.learner = self.learner\n",
    "        self.loss_b.learner = self.learner\n",
    "        loss_a = self.loss_a(out, tgt)\n",
    "        loss_b = self.loss_b(out, tgt)\n",
    "        return loss_a * self.a + loss_b * self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ember.metric import *\n",
    "\n",
    "class AvgDistMetric(ExpAvgMetric):\n",
    "    is_train = True\n",
    "    do_reporting = True\n",
    "    name = \"avg dist\"\n",
    "    def step(self):\n",
    "        with torch.amp.autocast(device_type=self.learner.device, enabled=False):\n",
    "            out = self.learner.preds\n",
    "            tgt = self.learner.y\n",
    "            B, L, _ = out.shape\n",
    "            _, mask = self.learner.x.get()\n",
    "            m = mask.unsqueeze(-1) # (B,L,1)\n",
    "\n",
    "            out = out.to(torch.float32)\n",
    "            tgt = tgt.to(torch.float32)\n",
    "            m = m.to(torch.float32)\n",
    "\n",
    "            # First calculate the translation vector\n",
    "            # that would be applied, out and tgt\n",
    "            # are both centered\n",
    "            # Making sure to multiply by w so the\n",
    "            # bad coordinates remain masked out\n",
    "\n",
    "            # Calculates (B, 1, 1) / (B, 1, 1)\n",
    "            mu_out = (out * m).sum(dim=1, keepdim=True) / (m.sum(dim=1, keepdim=True) + 1e-8)\n",
    "            mu_tgt = (tgt * m).sum(dim=1, keepdim=True) / (m.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "            out = out - mu_out\n",
    "            tgt = tgt - mu_tgt\n",
    "\n",
    "            # Scale up so normalization is not\n",
    "            # considered in the distances\n",
    "            for i in range(3):\n",
    "                out[:, :, i] *= stds[i]\n",
    "                tgt[:, :, i] *= stds[i]\n",
    "\n",
    "            # Get the cross-variance matrix\n",
    "            cross_var = (out * m).transpose(-1, -2) @ (tgt * m)\n",
    "            # Then find the singular value decomposition\n",
    "            U, _, Vt = torch.linalg.svd(cross_var)\n",
    "\n",
    "            rot_mat = Vt.transpose(-1,-2) @ U.transpose(-1,-2)\n",
    "            flip = torch.det(rot_mat) < 0.0\n",
    "            if flip.any().item():\n",
    "                Vt = Vt.clone() # Clone so gradients don't get destroyed\n",
    "                Vt[flip, -1, :] *= -1.0\n",
    "                rot_mat = Vt.transpose(-1,-2) @ U.transpose(-1,-2)\n",
    "\n",
    "            out_aligned = out @ rot_mat\n",
    "            diff = (tgt - out_aligned) * m\n",
    "\n",
    "            # Making sure to average each sample\n",
    "            rmsd = torch.sqrt((diff ** 2).sum(dim=(-1, -2)) / (m.sum(dim=(-1, -2)) + 1e-8) + 1e-8) # (B)\n",
    "\n",
    "            self.avg.step(float(rmsd.mean().detach().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quinn/miniconda3/lib/python3.13/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating batch size of 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>valid loss</th>\n",
       "      <th>avg dist</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='4206' class='' max='8839' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      47.58% [4206/8839 14:50&lt;16:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ember import Learner\n",
    "\n",
    "model = Model()\n",
    "optim = torch.optim.AdamW(model.parameters())\n",
    "learner = Learner(model, optim, train_loader, test_loader, loss_fn=HybridLoss(), clip_grads=1, accum=16,\n",
    "                 metrics = [LRMetric(), TrainLossMetric(), ValidLossMetric(), AvgDistMetric()]\n",
    ")\n",
    "\n",
    "learner.fit_one_cycle(num_epochs, max_lr=1e-3)\n",
    "\n",
    "learner.save(\"./exports/stanford/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot(\"train loss\", \"valid loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot(\"avg dist\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15231210,
     "sourceId": 118765,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
